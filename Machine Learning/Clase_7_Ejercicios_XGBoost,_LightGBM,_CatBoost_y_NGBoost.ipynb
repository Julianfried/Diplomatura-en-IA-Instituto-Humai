{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julianfried/Diplomatura-en-IA-Instituto-Humai/blob/main/Machine%20Learning/Clase_7_Ejercicios_XGBoost%2C_LightGBM%2C_CatBoost_y_NGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef5kcJXltmFv"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/machine_learning/blob/main/7_XGBoost/Ejercicios/Ejercicios.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>"
      ],
      "id": "Ef5kcJXltmFv"
    },
    {
      "cell_type": "markdown",
      "id": "c3ea51a2",
      "metadata": {
        "id": "c3ea51a2"
      },
      "source": [
        "# Ejercicios XGBoost, LightGBM, CatBoost y NGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SNylqREBCMf2",
      "metadata": {
        "id": "SNylqREBCMf2"
      },
      "source": [
        "Recuerden activar la opción de acelerador por hardaware \"gpu\" La cual se encuentra en \"Entorno de ejecución\" y dentro de \"cambiar tipo de entorno de ejecución\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a67b451",
      "metadata": {
        "id": "1a67b451"
      },
      "source": [
        "## Diseño de Modelo XGBoost para predicción de salarios\n",
        "Utilizando la librería XGBoost:\n",
        "1. Limpie el Dataset eliminando los valores nulos y conviertendo las variables categóricas mediante OneHotEncoding o similar.\n",
        "2. Divida el conjunto de datos en datos de entrenamiento y prueba.\n",
        "3. Implemente un modelo XGBoost para predecir si una persona gana más de 50K en función de las otras características y entrénelo con el set de entrenamiento.\n",
        "4. Evalúe el rendimiento del modelo usando el conjunto de prueba y la métrica ROC_AUC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "nJvvIkDZ8Ybn",
      "metadata": {
        "id": "nJvvIkDZ8Ybn"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "mQW0xknNCxRu",
      "metadata": {
        "id": "mQW0xknNCxRu"
      },
      "outputs": [],
      "source": [
        "# Leer el dataset\n",
        "df = pd.read_csv(\"https://datasets-humai.s3.amazonaws.com/datasets/adult_train.csv\")\n",
        "\n",
        "# Limpieza de datos y Encoding\n",
        "df = df.replace('?', np.nan)\n",
        "df = df.dropna()\n",
        "ohe = OneHotEncoder()\n",
        "df_encoded = ohe.fit_transform(df)\n",
        "\n",
        "\n",
        "# Data Split\n",
        "X = df_encoded[:, :-1]\n",
        "y = df_encoded[:, -1]\n",
        "\n",
        "# Convertir las matrices dispersas a arreglos NumPy\n",
        "X= X.toarray()\n",
        "y= y.toarray().ravel()\n",
        "\n",
        "# División de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X[:, :-1], y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "df2e77f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df2e77f4",
        "outputId": "a6e76848-6521-4eca-f4eb-22ecedd30c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El resultado de ROC-AUC es: 0.7336191994008351\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "xgb_cl = xgb.XGBClassifier(objective= 'binary:logistic', n_estimators=10, seed=42, tree_method='gpu_hist')\n",
        "xgb_cl.fit(X_train, y_train)\n",
        "# Evaluación\n",
        "preds= xgb_cl.predict(X_test)\n",
        "auc_score_xgboost = roc_auc_score(y_test, preds)\n",
        "print('El resultado de ROC-AUC es:',auc_score_xgboost)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1LykjecF9UFK",
      "metadata": {
        "id": "1LykjecF9UFK"
      },
      "source": [
        "## Empleo de Lightgbm para predicciones salariales\n",
        "Implemente y entrene un modelo Lightgbm utilizando el dataset adult para predecir el salario de una persona. Evalúe el rendimiento del modelo usando el conjunto de datos de prueba y la métrica ROC_AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ToRRQKpT9UZR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToRRQKpT9UZR",
        "outputId": "b125ca96-0bde-4bc6-a15d-437d9c4a1f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5978, number of negative: 18151\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002902 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2550\n",
            "[LightGBM] [Info] Number of data points in the train set: 24129, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247752 -> initscore=-1.110640\n",
            "[LightGBM] [Info] Start training from score -1.110640\n",
            "El resultado de ROC-AUC es: 0.851819701898081\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Crear el dataset LightGBM\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "\n",
        "# Definir los parámetros del modelo LightGBM\n",
        "params = {\n",
        "    'objective':'binary',\n",
        "    'metric':'auc',\n",
        "    'seed':42\n",
        "}\n",
        "\n",
        "# Entrenar el modelo LightGBM en la GPU\n",
        "lgbm_cl = lgb.train(params, train_data,num_boost_round=1)\n",
        "\n",
        "# Evaluación\n",
        "preds = lgbm_cl.predict(X_test)\n",
        "auc_score_lightgmb = roc_auc_score(y_test, preds)\n",
        "print('El resultado de ROC-AUC es:',auc_score_lightgmb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f12c98",
      "metadata": {
        "id": "a5f12c98"
      },
      "source": [
        "## Empleo de CatBoost para predicciones salariales\n",
        "Implemente y entrene un modelo CatBoost utilizando el dataset adult para predecir el salario de una persona. Evalúe el rendimiento del modelo usando el conjunto de datos de prueba y la métrica ROC_AUC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dgtCFv-85J4S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgtCFv-85J4S",
        "outputId": "854bcdd6-9621-448a-9d06-a970f474f67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c8d1944b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8d1944b",
        "outputId": "8589e144-58a6-4cbf-cc00-394ebd5ed1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El resultado de ROC-AUC es: 0.7472210247634474\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Modelo\n",
        "catb_cl = CatBoostClassifier(verbose=0, n_estimators=100, task_type='GPU')\n",
        "catb_cl.fit(X_train, y_train)\n",
        "# Evaluación\n",
        "preds = catb_cl.predict(X_test)\n",
        "auc_score_catb = roc_auc_score(y_test, preds)\n",
        "print('El resultado de ROC-AUC es:',auc_score_catb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pAyfiT20B9zo",
      "metadata": {
        "id": "pAyfiT20B9zo"
      },
      "source": [
        "## Empleo de NGBoost para predicciones salariales\n",
        "Implemente y entrene un modelo NGBoost utilizando el dataset adult para predecir el salario de una persona. Evalúe el rendimiento del modelo usando el conjunto de datos de prueba y la métrica ROC_AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8Mpj9mkbAqpL",
      "metadata": {
        "id": "8Mpj9mkbAqpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c29e395-aad9-47e0-a988-989cd40a0761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ngboost\n",
            "  Downloading ngboost-0.4.1-py3-none-any.whl (33 kB)\n",
            "Collecting lifelines>=0.25 (from ngboost)\n",
            "  Downloading lifelines-0.27.7-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.4/409.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from ngboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from ngboost) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from ngboost) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from ngboost) (1.10.1)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.10/dist-packages (from ngboost) (4.65.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines>=0.25->ngboost) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines>=0.25->ngboost) (1.6.2)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines>=0.25->ngboost)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines>=0.25->ngboost)\n",
            "  Downloading formulaic-0.6.4-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->ngboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->ngboost) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->ngboost) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->ngboost) (3.2.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.5->lifelines>=0.25->ngboost) (0.18.3)\n",
            "Collecting astor>=0.8 (from formulaic>=0.2.2->lifelines>=0.25->ngboost)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines>=0.25->ngboost)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->ngboost) (1.16.0)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=6f0bf8773f8f0b3158865c85d316928c8efe88337cda57759daf504f5addde28\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, astor, autograd-gamma, formulaic, lifelines, ngboost\n",
            "Successfully installed astor-0.8.1 autograd-gamma-0.5.0 formulaic-0.6.4 interface-meta-1.3.0 lifelines-0.27.7 ngboost-0.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ngboost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c50922f",
      "metadata": {
        "id": "6c50922f"
      },
      "source": [
        "Aclaración: El empleo del modelo NGBoost no podria correr en el colab debido a que este tiene un limite computacional. Debido a ello se reduce la dimensionalidad de los datos Ipara poder aplicar el modelo. Para ello se corre el siguiente codigo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ec1dc463",
      "metadata": {
        "id": "ec1dc463"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Reducción de dimensionalidad con PCA\n",
        "pca = PCA(n_components=10)  # Número de componentes principales deseados\n",
        "X_pca = pca.fit_transform(X[:, :-1])\n",
        "\n",
        "# División de datos en entrenamiento y prueba con datos reducidos por PCA\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convertir las etiquetas a formato entero\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "TXULEfLqAnEz",
      "metadata": {
        "id": "TXULEfLqAnEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95999ea2-ac1e-4633-e28e-93c5b8388bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iter 0] loss=0.5599 val_loss=0.0000 scale=2.0000 norm=4.0000\n",
            "El resultado de ROC-AUC es: 0.6848710881199027\n"
          ]
        }
      ],
      "source": [
        "from ngboost import NGBClassifier\n",
        "from ngboost.distns import Bernoulli # Bernoulli actua como la distribución de la clase Dist para problemas de clasificación binaria\n",
        "\n",
        "# Modelo\n",
        "ngb_cl = NGBClassifier(Dist=Bernoulli, n_estimators=100)\n",
        "ngb_cl.fit(X_train, y_train)\n",
        "\n",
        "# Evaluación\n",
        "preds = ngb_cl.predict(X_test)\n",
        "auc_score_ngb = roc_auc_score(y_test, preds)\n",
        "print('El resultado de ROC-AUC es:',auc_score_ngb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d08ed568",
      "metadata": {
        "id": "d08ed568"
      },
      "source": [
        "## Comparación de Modelos\n",
        "Compare el rendimiento de cada modelo y determine cuál se desempeña mejor en función de la métrica ROC_AUC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8etTJn8CaNp4",
      "metadata": {
        "id": "8etTJn8CaNp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3b724b-fc41-4d7a-8141-6ed3820c58cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost AUC Score: 0.7336191994008351\n",
            "LightGBM AUC Score: 0.851819701898081\n",
            "CatBoost AUC Score: 0.7472210247634474\n",
            "NGBoost AUC Score: 0.6848710881199027\n"
          ]
        }
      ],
      "source": [
        "print(f'XGBoost AUC Score: {auc_score_xgboost}')\n",
        "print(f'LightGBM AUC Score: {auc_score_lightgmb}')\n",
        "print(f'CatBoost AUC Score: {auc_score_catb}')\n",
        "print(f'NGBoost AUC Score: {auc_score_ngb}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}