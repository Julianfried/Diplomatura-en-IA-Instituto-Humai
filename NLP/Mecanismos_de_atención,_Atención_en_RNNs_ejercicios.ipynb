{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vAGmz5MuAvRA",
        "TX3dksqNhj6k"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julianfried/Diplomatura-en-IA-Instituto-Humai/blob/main/NLP/Mecanismos_de_atenci%C3%B3n%2C_Atenci%C3%B3n_en_RNNs_ejercicios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/NLP/5_Atencion/ejercicios/ejercicios.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>"
      ],
      "metadata": {
        "id": "UJl0RizqktN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usando atención."
      ],
      "metadata": {
        "id": "CYGAfF0TYCcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Volveremos a usar las interfaces que usamos antes."
      ],
      "metadata": {
        "id": "IP6FXhRiG6zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # Más tarde puede haber argumentos adicionales\n",
        "    # (por ejemplo, longitud para excluir el relleno)\n",
        "    def forward(self, X, *args):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "IMiAMZKaS5ke"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"The base decoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # Más tarde puede haber argumentos adicionales\n",
        "    # (por ejemplo, longitud para excluir el relleno)\n",
        "    def init_state(self, enc_outputs, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "AjWpa1OkR9N6"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, enc_X, dec_X, *args):\n",
        "        enc_outputs = self.encoder(enc_X, *args)\n",
        "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
        "        return self.decoder(dec_X, dec_state)[0]"
      ],
      "metadata": {
        "id": "PzedBSz3XVjW"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 1\n",
        "\n",
        "Implementar un Encoder con GRU:\n",
        "\n",
        "El constructor debe recibir los siguientes parametros:\n",
        "\n",
        "`__init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim,\n",
        "                 num_layers, dropout)`\n",
        "  * `input_dim`: tamaño del vocabulario\n",
        "  * `emb_dim`: tamaño del vector a la salida de una capa de embeddings\n",
        "  * `enc_hid_dim`: tamaño del vector de estado oculto a la salida de GRU\n",
        "  * `dec_hid_dim`: tamaño del vector de estado oculto a la salida de GRU **PERO EN EL DECODER**\n",
        "  * `num_layers`: número de capas de GRU\n",
        "  > NOTA: ese número de capas sera el mismo para el decoder y el encoder\n",
        "  * `dropout`: probabilidad de dropout\n",
        "\n",
        "La red debe hacer lo siguiente:\n",
        "  1. Recibe un minilote de secuencias de tokens `src` y lo alimenta a una capa de `Embedding`\n",
        "  1. Toma la salida de la capa `Embedding`y la usa en una `GRU` bidireccional, multicapa.\n",
        "  2. Usar una capa densa `Linear`, para adaptar los estados ocultos del encoder al decoder. Esta capa recibe entra con `enc_hid_dim * num_layers * 2` y devuelve `dec_hid_dim * num_layers`\n",
        "    * `GRU` bidireccional tiene como salida el último estado oculto de cada capa `hidden` y la secuencia temporal de los estado ocultos de la última capa `outputs`.\n",
        "    * `hidden` tiene  la forma `[n_capas * num_ direcciones, batch, hid_dim]`. Los estados ocultos estan ordenadados de la siguiente forma `[forward_1, backward_1, forward_2, backward_2, ...]`\n",
        "    * deberá adaptar el tensor `hidden` para que tenga la forma `[1, batch, hid_dim * n_capas * num_ direcciones]` y luego alimentarlo a la capa lineal.\n",
        "    * finalmente, deberá volver a adaptar la salida para que tenga la forma `[n_capas * num_ direcciones, batch, hid_dim]`.\n",
        "    * Recuerde que el decoder es unidireccional\n",
        "\n",
        "  1. La red debe devolver la salida de la capa densa y los `outputs` de GRU"
      ],
      "metadata": {
        "id": "VXz8FmNqHjjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_RNN(module):\n",
        "    if type(module) == nn.Linear:\n",
        "         nn.init.xavier_uniform_(module.weight)\n",
        "    if type(module) == nn.GRU:\n",
        "        for param in module._flat_weights_names:\n",
        "            if \"weight\" in param:\n",
        "                nn.init.xavier_uniform_(module._parameters[param])\n",
        "\n",
        "class ATTNEncoder(Encoder):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim,\n",
        "                 num_layers, dropout):\n",
        "        ### inserte su código\n",
        "\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, num_layers,\n",
        "                          bidirectional = True, dropout = dropout)\n",
        "        self.fc = nn.Linear(enc_hid_dim * num_layers * 2,\n",
        "                            dec_hid_dim * num_layers)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.apply(init_RNN)\n",
        "    \"\"\"\n",
        "    Diferencias con el código de la clase anterior:\n",
        "        * Trabajamos con 1 sola capa\n",
        "        * RNN bidireccional ¿Que ventaja trae?\n",
        "        * Aplicamos un capa densa adicional para convertir la\n",
        "          salida bidireccional en una unidireccional\n",
        "        * Hay variables que no estamos guardando como la dimensión\n",
        "          de los estados ocultos.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, src):\n",
        "\n",
        "        ### inserte su código\n",
        "\n",
        "        #src = [src len, batch size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = hidden.chunk(self.num_layers * 2,dim=0)\n",
        "        hidden = torch.cat(hidden,dim=-1)\n",
        "        hidden = torch.tanh(self.fc(hidden))\n",
        "        #hidden = [1, batch size, dec hid dim * num layers * num directions]\n",
        "\n",
        "        hidden = hidden.chunk(self.num_layers, dim=-1)\n",
        "        hidden = torch.cat(hidden,dim=0)\n",
        "\n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #hidden = [num layers, batch size, dec hid dim ]\n",
        "\n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "cq26dXXihAJw"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use esta  celda para verificar que todo funcione como corresponde"
      ],
      "metadata": {
        "id": "r9ottjhfQYo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, embed_size, num_hiddens, num_layers = 10, 8, 16, 2\n",
        "batch_size, num_steps = 4, 9\n",
        "\n",
        "encoder = ATTNEncoder(vocab_size, embed_size, num_hiddens, num_hiddens,\n",
        "                      num_layers, 0.5)\n",
        "X = torch.zeros((num_steps, batch_size), dtype=torch.int32)\n",
        "outputs, state = encoder(X)\n",
        "print(outputs.shape, (num_steps,batch_size,num_hiddens * 2), \"todos los numeros  deben coincidir\")\n",
        "print(state.shape, (num_layers, batch_size,num_hiddens), \"todos los numeros  deben coincidir\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHGX_MC5jXC0",
        "outputId": "80b87371-0749-48db-a7f4-9b8ecca00492"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 4, 32]) (9, 4, 32) todos los numeros  deben coincidir\n",
            "torch.Size([2, 4, 16]) (2, 4, 16) todos los numeros  deben coincidir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Implementar un Decoder con GRU:\n",
        "\n",
        "El constructor debe recibir los siguientes parametros:\n",
        "\n",
        "`__init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, num_layers, dropout, attention):`\n",
        "  * `output_dim`: tamaño del vector del vocabulario\n",
        "  * `emb_dim`: tamaño del vector a la salida de una capa de embeddings\n",
        "  * `enc_hid_dim`: tamaño del vector de estado oculto a la salida de GRU\n",
        "  * `dec_hid_dim`: tamaño del vector de estado oculto a la salida de GRU **PERO EN EL DECODER**\n",
        "  * `num_layers`: número de capas de GRU\n",
        "  > NOTA: ese número de capas sera el mismo para el decoder y el encoder\n",
        "  * `dropout`: probabilidad de dropout\n",
        "  * `attention`: capa de atención.\n",
        "\n",
        "La red debe hacer lo siguiente:\n",
        "  1. Recibe un minilote de secuencias de tokens `input`, el estado oculto a la salida del encoder `hidden` y la secuencia de estados del decoder `encoder_outputs`\n",
        "  1. Aplicamos un `unsqueeze` a `input` en la dimensión `0`\n",
        "  1. Usamos `input`para alimentarlo a la alimenta a una capa de `Embedding`\n",
        "  1. Alimentamos a la capa de atención `attention` con `hidden` y `encoder_outputs` para generar los pesos `a`.\n",
        "  2. Generamos un estado con atención `weighted` a partir de los pesos `a` y `encoder_outputs`\n",
        "    * `a` tiene la forma `[batch_size, sequence_len]` y `encoder_outputs` tiene la forma `[sequence_len, batch_size, end_hid_dim]` debemos transformarlos de la siguiente manera:\n",
        "      * `a` --> `[batch_size, 1, sequence_len]`\n",
        "      * `encoder_outputs` --> `[batch_size, sequence_len, end_hid_dim]`\n",
        "\n",
        "      De esa manera podemos aplicar la función bmm de torch (batched matrix multiplication)\n",
        "    * `weighted` tendra la forma `[batch_size, 1, sequence_len]`, pero necesitamos que tenga la forma `[1, batch_size, sequence_len]`\n",
        "  3. Concatenamos `weighted` con la salida de la capa de embeddings en el tensor `input_rnn`\n",
        "  4. Le damos a nuestra GRU, `input_rnn` y `hidden`. Recuerde que esta nos dara un nuevo `hidden` junto con un tensor `outputs`\n",
        "  4. Tomamos la salida de nuestra GRU `outputs`, el tensor `weighted` y la salida del embedding y las concatenamos, eliminando la primera dimensión (`squeeze` en `0`)\n",
        "  2. A la concatenación anterior, se la enviamos a una capa densa que nos predice el próximo token.\n",
        "  3. La red devuelve las predicciones junto con el estado oculto `hidden recien calculado.`"
      ],
      "metadata": {
        "id": "TLkounCcQV-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ATTNDecoder(Decoder):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, num_layers, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        ### inserte su código\n",
        "\n",
        "        self.attention = attention #atención!\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim,\n",
        "                          num_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim,\n",
        "                                output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.apply(init_RNN)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "\n",
        "        ### inserte su código\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
        "\n",
        "        return prediction, hidden"
      ],
      "metadata": {
        "id": "7MiiT6JPfU2o"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "Implementar un Decoder con GRU:\n",
        "\n",
        "El constructor debe recibir los siguientes parametros:\n",
        "\n",
        "`    def __init__(self, enc_hid_dim, dec_hid_dim, num_layers):\n",
        "`\n",
        "  * `enc_hid_dim`: tamaño del vector de estado oculto a la salida de GRU\n",
        "  * `dec_hid_dim`: tamaño del vector de estado oculto a la salida de GRU **PERO EN EL DECODER**\n",
        "  * `num_layers`: número de capas de GRU\n",
        "  > NOTA: ese número de capas sera el mismo para el decoder y el encoder\n",
        "\n",
        "La red debe hacer lo siguiente:\n",
        "\n",
        "  1. Recibe el estado oculto `hidden` y la salida del encoder `encoder_outputs`\n",
        "  1. Convertimos el estado oculto `hidden` de un tensor de la forma `[num_layers, batch size, dec hid dim]` a uno de la forma `[batch size, 1, dec hid dim * num layers]`\n",
        "  1. Repetimos en la dimensión 1 al tensor  `len_src` veces. Pasamos de un tensor de la forma `[batch size, 1, dec hid dim * num layers]` a uno de la forma `[batch size, src len, dec hid dim * num layers]`\n",
        "  1. Convertimos el estado oculto `encoder_outputs` de un tensor de la forma `[src len, batch size, enc hid dim]` a uno de la forma `[batch size, src len, enc hid dim * num direction]`\n",
        "  2. Aplicamos una capa densa seguida de una `tanh`\n",
        "  3. Luego aplicamos una segunda capa densa. La salida debe tener la forma `[batch size, src len, 1]`. Por esta razón eliminaremos la última dimensión usando unsqueeze\n",
        "  4. Devolvemos los pesos luego de aplicar un softmax en la dimensión `1`. La salida debe ser de la forma `[batch size, src len]`\n"
      ],
      "metadata": {
        "id": "VntQJk5-a75A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        ### inserte su código\n",
        "\n",
        "        \"\"\"\n",
        "            Recordemos que tenemos 2 MLP:\n",
        "                * Uno para el output del encoder\n",
        "                * otro para generar el estado oculto.\n",
        "        \"\"\"\n",
        "        size_input = enc_hid_dim * 2 + dec_hid_dim * num_layers\n",
        "        size_output =  dec_hid_dim * num_layers\n",
        "        self.attn = nn.Linear(size_input, size_output)\n",
        "        self.v = nn.Linear(size_output, 1, bias = False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "\n",
        "        ### inserte su código\n",
        "\n",
        "        #hidden = [num_layers, batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "\n",
        "        num_layers = hidden.shape[0]\n",
        "        hidden = hidden.chunk(num_layers, dim=0)\n",
        "        hidden = torch.cat(hidden, dim=-1)\n",
        "        hidden = hidden.squeeze(0)\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        \"\"\"\n",
        "        Repetimos el estado oculto del decoder src_len veces\n",
        "        \"\"\"\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        \"\"\"\n",
        "        Cambiamos el orden de los índice.\n",
        "        \"\"\"\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        #hidden = [batch size, src len, dec hid dim * num layers]\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "\n",
        "        \"\"\"\n",
        "        Aplicamos primera capa de MLP\n",
        "        \"\"\"\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n",
        "\n",
        "        #energy = [batch size, src len, dec hid dim]\n",
        "\n",
        "        \"\"\"\n",
        "        Aplicamos segunda capa de MLP\n",
        "        \"\"\"\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "\n",
        "        #attention= [batch size, src len]\n",
        "        return F.softmax(attention, dim=1)"
      ],
      "metadata": {
        "id": "JmKZKmnFdRBJ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "class ATTNSeq2Seq(EncoderDecoder):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__(encoder, decoder)\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \"\"\"\n",
        "        Eliminamos el assert\n",
        "        \"\"\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "\n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "\n",
        "        \"\"\"\n",
        "        Como ahora usamos anteción, el estado inicial es manejado\n",
        "        por el decoder.\n",
        "        \"\"\"\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "\n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "\n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "MVoz70K8rY9W"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# La siguiente celda no funcionará hasta que se cargue el vocabulario\n",
        "# y se establezca el índice de padding\n",
        "#loss = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "6_0Mabon-u2g"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargando los Datos\n",
        "\n"
      ],
      "metadata": {
        "id": "vAGmz5MuAvRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import re\n",
        "from shutil import unpack_archive\n",
        "\n",
        "data = None\n",
        "!wget -O spa-eng.zip http://www.manythings.org/anki/spa-eng.zip\n",
        "if not os.path.isfile(\"spa.txt\"):\n",
        "    unpack_archive('./spa-eng.zip', extract_dir='./', format='zip')\n",
        "with open('./spa.txt', encoding='utf-8') as f:\n",
        "    data = f.read()\n",
        "    data = re.sub(\"\\tCC-BY 2\\.0.*\",\"\",data) # acá elimino información adicional\n",
        "    data = re.sub(r\"[\\u202f]|[\\xa0]\",\" \",data) # aca saco caracteres raros\n",
        "    data = re.sub(\"([,\\.:;!?])\",\" \\\\1\",data) # aca  y abajo tokenizo puntuación\n",
        "    data = re.sub(\"([¡¿])\",\"\\\\1 \",data).lower()\n"
      ],
      "metadata": {
        "id": "S_WUXllMA-3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f3608a-326b-48d7-c965-467ed0d9c1ce"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-03 14:48:19--  http://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5394805 (5.1M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "spa-eng.zip         100%[===================>]   5.14M  26.0MB/s    in 0.2s    \n",
            "\n",
            "2023-11-03 14:48:19 (26.0 MB/s) - ‘spa-eng.zip’ saved [5394805/5394805]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IopirAQHVvQt",
        "outputId": "93e6e7d7-0e2a-482a-c99e-4eb41f856004"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go .\tve .\n",
            "go .\tvete .\n",
            "go .\tvaya .\n",
            "go .\tváyase .\n",
            "hi .\thola .\n",
            "run !\t¡ corre !\n",
            "run !\t¡ corran !\n",
            "run !\t¡\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "SRC_IDX, TGT_IDX = 0, 1\n",
        "\n",
        "SEED = 12312\n",
        "\n",
        "data2 = data.split('\\n')\n",
        "random.seed(SEED)\n",
        "random.shuffle(data2)\n",
        "\n",
        "data_list = []\n",
        "for i, line in enumerate(data2):\n",
        "    parts = line.split('\\t')\n",
        "    if len(parts) == 2:\n",
        "        # Skip empty tokens\n",
        "        new_src = [t for t in f'{parts[SRC_IDX]} <eos>'.split(' ') if t]\n",
        "        new_tgt = [t for t in f'<bos> {parts[TGT_IDX]} <eos>'.split(' ') if t]\n",
        "        length_src = len(new_src)\n",
        "        data_list.append((new_src, length_src, new_tgt))\n",
        "\n",
        "print(data_list[0][0], data_list[0][-1])\n",
        "print(len(data_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VeFH-9-BuSX",
        "outputId": "85ed23a5-754c-4206-9c8b-67a0e690efc8"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['they', 'want', 'me', '.', '<eos>'] ['<bos>', 'ellos', 'me', 'quieren', 'a', 'mí', '.', '<eos>']\n",
            "140868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "n = len(data_list)\n",
        "split1, split2 = int(0.7*n), int(0.9*n)\n",
        "train_list = data_list[:split1]\n",
        "val_list = data_list[split1:split2]\n",
        "test_list = data_list[split2:]\n",
        "\n",
        "counter_src, counter_tgt = Counter(), Counter()\n",
        "for i in range(len(train_list)):\n",
        "  counter_src.update(train_list[i][0])\n",
        "  counter_tgt.update(train_list[i][-1])\n",
        "\n",
        "vocab_src = vocab(counter_src, min_freq = 2,\n",
        "              specials=('<unk>', '<eos>', '<bos>', '<pad>'))\n",
        "vocab_src.set_default_index(vocab_src['<unk>'])\n",
        "\n",
        "vocab_tgt = vocab(counter_tgt, min_freq = 2,\n",
        "              specials=('<unk>', '<eos>', '<bos>', '<pad>'))\n",
        "vocab_tgt.set_default_index(vocab_tgt['<unk>'])\n"
      ],
      "metadata": {
        "id": "MlU1LfacCAhT"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "class BucketSampler(Sampler):\n",
        "\n",
        "    def __init__(self, batch_size, train_list):\n",
        "        self.length = len(train_list)\n",
        "        self.train_list = train_list\n",
        "        self.batch_size = batch_size\n",
        "        indices = [(i, s[1]) for i, s in enumerate(self.train_list)]\n",
        "        random.seed(SEED)\n",
        "        random.shuffle(indices)\n",
        "        pooled_indices = []\n",
        "        # creamos minilotes de tamaños similares\n",
        "        for i in range(0, len(indices), batch_size * 100):\n",
        "            pooled_indices.extend(sorted(indices[i:i + batch_size * 100],\n",
        "                                         key=lambda x: x[1], reverse=True))\n",
        "\n",
        "        self.pooled_indices = pooled_indices\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(0, len(self.pooled_indices), self.batch_size):\n",
        "            yield [idx for idx, _ in self.pooled_indices[i:i + self.batch_size]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.length + self.batch_size - 1) // self.batch_size"
      ],
      "metadata": {
        "id": "YjpbkiK2CMV6"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "SRC_PAD_IDX = vocab_src['<pad>']\n",
        "TGT_PAD_IDX = vocab_tgt['<pad>']\n",
        "\n",
        "def collate_batch(batch):\n",
        "    text_src, length_list, text_tgt_in, text_tgt_out = [], [], [], []\n",
        "    for (src, length, tgt) in batch:\n",
        "        # convertimos el texto en tokens\n",
        "        processed_src = torch.tensor([vocab_src[token] for token in src])\n",
        "        processed_tgt = torch.tensor([vocab_tgt[token] for token in tgt])\n",
        "        text_src.append(processed_src)\n",
        "        text_tgt_in.append(processed_tgt[:-1])\n",
        "        text_tgt_out.append(processed_tgt[1:])\n",
        "        # guardamos la longitud de cada token\n",
        "        length_list.append(length)\n",
        "    # armamos la tupla que conformara un ejemplo de minilote.\n",
        "    result = (pad_sequence(text_src, padding_value=SRC_PAD_IDX),\n",
        "              pad_sequence(text_tgt_in, padding_value=TGT_PAD_IDX),\n",
        "              pad_sequence(text_tgt_out, padding_value=TGT_PAD_IDX),)\n",
        "    return result"
      ],
      "metadata": {
        "id": "ipx7mj_YCOrw"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64  # A batch size of 64\n",
        "\n",
        "train_bucket = BucketSampler(batch_size, train_list)\n",
        "train_iter = DataLoader(train_list,\n",
        "                          batch_sampler=train_bucket,\n",
        "                          collate_fn=collate_batch)\n",
        "\n",
        "val_bucket = BucketSampler(batch_size, val_list)\n",
        "val_iter = DataLoader(val_list,\n",
        "                          batch_sampler=val_bucket,\n",
        "                          collate_fn=collate_batch)\n",
        "\n",
        "test_bucket = BucketSampler(batch_size, test_list)\n",
        "test_iter = DataLoader(test_list,\n",
        "                          batch_sampler=test_bucket,\n",
        "                          collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "2T5ppiECCSCv"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src, input, out = next(iter(test_iter))\n",
        "\n",
        "a = [vocab_src.get_itos()[token] for example in src.T[:1] for token in example]\n",
        "b = [vocab_tgt.get_itos()[token] for example in out.T[:1] for token in example]\n",
        "c = [vocab_tgt.get_itos()[token] for example in input.T[:1] for token in example]\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "id": "kpKpN6OJCUEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d3669d-16f6-435d-b340-a557135de4fa"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['you', 'can', 'fool', 'some', 'of', 'the', 'people', 'all', 'of', 'the', 'time', ',', 'and', 'all', 'of', 'the', 'people', 'some', 'of', 'the', 'time', ',', 'but', 'you', \"can't\", 'fool', 'all', 'of', 'the', 'people', 'all', 'of', 'the', 'time', '.', '<eos>']\n",
            "['se', 'puede', 'engañar', 'a', 'algunas', 'personas', 'durante', 'todo', 'el', 'tiempo', 'y', 'a', 'todas', 'las', 'personas', 'por', 'algún', 'tiempo', ',', 'pero', 'no', 'se', 'puede', 'engañar', 'a', 'todo', 'el', 'mundo', 'todo', 'el', 'tiempo', '.', '<eos>']\n",
            "['<bos>', 'se', 'puede', 'engañar', 'a', 'algunas', 'personas', 'durante', 'todo', 'el', 'tiempo', 'y', 'a', 'todas', 'las', 'personas', 'por', 'algún', 'tiempo', ',', 'pero', 'no', 'se', 'puede', 'engañar', 'a', 'todo', 'el', 'mundo', 'todo', 'el', 'tiempo', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bucle de Entrenamiento"
      ],
      "metadata": {
        "id": "TX3dksqNhj6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src, tgt_input, tgt_out = batch\n",
        "        src, tgt_input, tgt_out = src.to(device), tgt_input.to(device), tgt_out.to(device)\n",
        "        #src: son las frases en el idioma origen que le pasaremos como entrada al encoder\n",
        "        #src.shape : [src len, batch size]\n",
        "        #tgt_input: son las frases en el idioma destino que le pasaremos como entrada al decoder (con `<bos>` como primer token y sin `<eos>`)\n",
        "        #tgt_out: son las frases en el idioma destino que usaremos para calcular la pérdida (con `<eos>` como finalizador de oración y sin `<bos>`)\n",
        "        #tgt.shape : [trg len, batch size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt_input)\n",
        "        #output = [trg len, batch size, output dim]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        #como la función de pérdida solo funciona en entradas 2d con objetivos 1d,\n",
        "        # necesitamos aplanar cada una de ellas con .view\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = tgt_out[1:].view(-1)\n",
        "        #trg = [trg len * batch size]\n",
        "        #output = [trg len * batch size, output dim]\n",
        "\n",
        "        #calculamos los gradientes\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        #recortamos los gradientes para evitar que exploten\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "I3lCQgDphwHn"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src, tgt_input, tgt_out = batch\n",
        "            src, tgt_input, tgt_out = src.to(device), tgt_input.to(device), tgt_out.to(device)\n",
        "            output = model(src, tgt_input, 0) #turn off teacher forcing\n",
        "            #output = [trg len, batch size, output dim]\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.view(-1, output_dim)\n",
        "            trg = tgt_out.view(-1)\n",
        "            #trg = [trg len * batch size]\n",
        "            #output = [trg len * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "1T33a6A6orp0"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "IpHOKK_mrT-Q"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento.\n",
        "\n",
        "Luego, entrenamos nuestro modelo, guardando los parámetros que nos den la mejor pérdida de validación."
      ],
      "metadata": {
        "id": "KCSWyK8uh7hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "INPUT_DIM = len(vocab_src.get_itos())\n",
        "OUTPUT_DIM = len(vocab_tgt.get_itos())\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, N_LAYERS)\n",
        "enc = ATTNEncoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = ATTNDecoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
        "\n",
        "model = ATTNSeq2Seq(enc, dec, device).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TGT_PAD_IDX)"
      ],
      "metadata": {
        "id": "-OcpXZ9OrzOf"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pzWdWzNhobv",
        "outputId": "0e291e6a-a283-4876-835e-bf1497a0f4ab"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 4m 2s\n",
            "\tTrain Loss: 4.071 | Train PPL:  58.644\n",
            "\t Val. Loss: 4.243 |  Val. PPL:  69.604\n",
            "Epoch: 02 | Time: 4m 1s\n",
            "\tTrain Loss: 2.910 | Train PPL:  18.361\n",
            "\t Val. Loss: 3.979 |  Val. PPL:  53.487\n",
            "Epoch: 03 | Time: 4m 0s\n",
            "\tTrain Loss: 2.576 | Train PPL:  13.147\n",
            "\t Val. Loss: 3.999 |  Val. PPL:  54.536\n",
            "Epoch: 04 | Time: 4m 0s\n",
            "\tTrain Loss: 2.420 | Train PPL:  11.246\n",
            "\t Val. Loss: 4.043 |  Val. PPL:  57.024\n",
            "Epoch: 05 | Time: 4m 1s\n",
            "\tTrain Loss: 2.347 | Train PPL:  10.457\n",
            "\t Val. Loss: 4.056 |  Val. PPL:  57.757\n",
            "Epoch: 06 | Time: 4m 0s\n",
            "\tTrain Loss: 2.302 | Train PPL:   9.992\n",
            "\t Val. Loss: 4.174 |  Val. PPL:  64.980\n",
            "Epoch: 07 | Time: 4m 1s\n",
            "\tTrain Loss: 2.270 | Train PPL:   9.683\n",
            "\t Val. Loss: 4.130 |  Val. PPL:  62.163\n",
            "Epoch: 08 | Time: 4m 1s\n",
            "\tTrain Loss: 2.253 | Train PPL:   9.521\n",
            "\t Val. Loss: 4.094 |  Val. PPL:  59.991\n",
            "Epoch: 09 | Time: 4m 2s\n",
            "\tTrain Loss: 2.239 | Train PPL:   9.387\n",
            "\t Val. Loss: 4.156 |  Val. PPL:  63.845\n",
            "Epoch: 10 | Time: 4m 2s\n",
            "\tTrain Loss: 2.236 | Train PPL:   9.354\n",
            "\t Val. Loss: 4.195 |  Val. PPL:  66.380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iter, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "id": "YuUf-GYFBUwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07814d50-166b-44fb-c46f-dfda89e58658"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 3.985 | Test PPL:  53.762 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicción"
      ],
      "metadata": {
        "id": "Il3Gm2jYDF6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src = \"i'm cold . <eos>\"\n",
        "tgt = \"tengo frío .\"\n",
        "\n",
        "### Solo debe generar predicciones, no hace falta que devuelva los pesos.\n",
        "def prediction(src, tgt, max_len):\n",
        "  tkn_src = [ vocab_src[tkn] for tkn in src.split(' ')]\n",
        "  input_src = torch.Tensor(tkn_src)\n",
        "  input_src = input_src.type(torch.int32)\n",
        "  input_src = input_src.unsqueeze(1)\n",
        "  input_src = input_src.to(device)\n",
        "\n",
        "  model.eval()\n",
        "  outputs, hidden = model.encoder(input_src)\n",
        "\n",
        "  final = []\n",
        "  input_tgt = torch.Tensor([vocab_tgt['<bos>']])\n",
        "  for i in range(max_len):\n",
        "      input_tgt = input_tgt.type(torch.int32)\n",
        "      input_tgt = input_tgt.to(device)\n",
        "      next_tkn, hidden = model.decoder(input_tgt, hidden, outputs)\n",
        "      input_tgt = next_tkn.argmax(1)\n",
        "      string = vocab_tgt.get_itos()[int(input_tgt)]\n",
        "      if string == '<eos>':\n",
        "          break\n",
        "      final.append(string)\n",
        "  return final\n",
        "\n",
        "final = prediction(src, tgt, 9)\n",
        "print(src)\n",
        "print(tgt)\n",
        "print(final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWJaRcsD5mY7",
        "outputId": "c59e9e59-67c4-436c-b388-3c16b4e4fb4b"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i'm cold . <eos>\n",
            "tengo frío .\n",
            "['frío', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "def bleu(pred_seq, label_seq, k):\n",
        "    # convertimos nuestras oraciones en secuencias de palabras\n",
        "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
        "\n",
        "    # calculamos la longitud\n",
        "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
        "\n",
        "    # iniciamos el primer valor de puntaje.\n",
        "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
        "\n",
        "    # ciclo\n",
        "    for n in range(1, min(k, len_pred) + 1):\n",
        "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
        "\n",
        "        for i in range(len_label - n + 1):\n",
        "            ## Generamos todos los n-gramas de tamaño i para labels\n",
        "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
        "\n",
        "        for i in range(len_pred - n + 1):\n",
        "            ## Generamos todos los n-gramas de tamaño i para labels\n",
        "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
        "                #contamos coincidencias.\n",
        "                num_matches += 1\n",
        "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
        "\n",
        "        # actualizamos score\n",
        "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
        "    return score"
      ],
      "metadata": {
        "id": "OYOE3PsrT20j"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bleu(' '.join(final),tgt,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD06uc3p9bdl",
        "outputId": "d464a3a3-c6ea-4f7d-ee77-7a42b4a9f988"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6065306597126334\n"
          ]
        }
      ]
    }
  ]
}